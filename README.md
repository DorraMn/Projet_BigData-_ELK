# âš¡ LogStream Studio - Plateforme de Monitoring Big Data

## ğŸ“‹ Vue d'ensemble

**LogStream Studio** est une plateforme complÃ¨te de monitoring et d'analyse de logs Big Data construite avec la stack ELK (Elasticsearch, Logstash, Kibana). Le projet intÃ¨gre MongoDB pour la gestion des mÃ©tadonnÃ©es, Redis pour le caching, et une application web Flask moderne avec systÃ¨me d'authentification JWT.

### Objectifs du Projet

- ğŸ¯ Centraliser et analyser des logs de diffÃ©rentes sources (CSV, JSON)
- ğŸ“Š Visualiser les donnÃ©es en temps rÃ©el via des dashboards interactifs
- ğŸ” SÃ©curiser l'accÃ¨s avec un systÃ¨me d'authentification robuste
- ğŸ“ˆ Fournir des statistiques et mÃ©triques en temps rÃ©el
- ğŸ” Permettre la recherche avancÃ©e dans les logs
- ğŸ’¾ Stocker et gÃ©rer efficacement les mÃ©tadonnÃ©es des uploads

ğŸ“ **Architecture ComplÃ¨te** : Consultez [ARCHITECTURE.md](./ARCHITECTURE.md) pour une vue dÃ©taillÃ©e de l'organisation du projet.

---

## ğŸš€ DÃ©marches de RÃ©alisation du Projet

### Phase 1 : Mise en Place de l'Infrastructure ELK

**Objectif** : DÃ©ployer la stack ELK de base avec Docker Compose

#### Ã‰tapes rÃ©alisÃ©es :

1. **Configuration Docker Compose**
   - CrÃ©ation du fichier `docker-compose.yml` avec 7 services
   - Configuration des volumes pour la persistance des donnÃ©es
   - Mise en place du rÃ©seau `elk_net` pour la communication inter-services
   - DÃ©finition des variables d'environnement dans `.env`

2. **DÃ©ploiement Elasticsearch**
   - Version 8.10.3 configurÃ©e en mode single-node
   - DÃ©sactivation de la sÃ©curitÃ© pour l'environnement de dÃ©veloppement
   - Mapping du port 9200 pour l'API REST
   - Volume `./data/elasticsearch` pour la persistance

3. **IntÃ©gration Kibana**
   - Configuration de la connexion Ã  Elasticsearch
   - Interface web accessible sur le port 5601
   - Personnalisation des dashboards pour l'analyse e-commerce

4. **Configuration Logstash**
   - CrÃ©ation de pipelines pour CSV et JSON dans `./pipeline/`
   - Configuration des inputs (file), filters (parsing) et outputs (Elasticsearch)
   - Mapping automatique vers les indices Elasticsearch

**RÃ©sultats** : Infrastructure ELK fonctionnelle et communicante

---

### Phase 2 : Ajout des Bases de DonnÃ©es (MongoDB & Redis)

**Objectif** : IntÃ©grer des bases de donnÃ©es pour la gestion des mÃ©tadonnÃ©es et le caching

#### Ã‰tapes rÃ©alisÃ©es :

1. **DÃ©ploiement MongoDB**
   - Container MongoDB version 7
   - Base de donnÃ©es `monitoring` avec collections :
     - `uploads` : MÃ©tadonnÃ©es des fichiers uploadÃ©s
     - `users` : Comptes utilisateurs (ajoutÃ© en Phase 5)
   - Mongo Express sur port 8081 pour l'administration web
   - Credentials : admin/admin123

2. **IntÃ©gration Redis**
   - DÃ©ploiement Redis pour le caching des sessions
   - Configuration de la persistance avec `dump.rdb`
   - Port 6379 exposÃ© pour les connexions

3. **Tests de Connexion**
   - VÃ©rification de la communication entre services
   - Tests CRUD sur MongoDB
   - Tests SET/GET sur Redis

**RÃ©sultats** : Bases de donnÃ©es opÃ©rationnelles et intÃ©grÃ©es Ã  l'Ã©cosystÃ¨me

---

### Phase 3 : DÃ©veloppement de l'Application Web Flask

**Objectif** : CrÃ©er une interface web moderne pour l'upload et la visualisation des logs

#### Ã‰tapes rÃ©alisÃ©es :

1. **Architecture Flask** (`webapp/app.py`)
   - Structure modulaire avec sÃ©paration des routes
   - Connexions aux 5 services (Elasticsearch, MongoDB, Redis, Kibana, Logstash)
   - Gestion des erreurs et fallbacks si services indisponibles

2. **SystÃ¨me de Fichiers**
   - Upload de fichiers CSV/JSON/TXT/LOG
   - Validation des extensions autorisÃ©es
   - Stockage dans `./data/uploads/` avec noms sÃ©curisÃ©s (secure_filename)
   - PrÃ©visualisation des 10 premiÃ¨res lignes

3. **IntÃ©gration avec Logstash**
   - Volume partagÃ© entre Flask et Logstash
   - Traitement automatique des fichiers uploadÃ©s
   - Injection dans Elasticsearch via les pipelines

4. **Base de DonnÃ©es**
   - Enregistrement des mÃ©tadonnÃ©es dans MongoDB :
     - Nom du fichier, taille, type MIME
     - Date d'upload, statut (saved/processed/error)
     - HÃ´te d'origine
   - RequÃªtes pour rÃ©cupÃ©rer l'historique des uploads

**RÃ©sultats** : Application web fonctionnelle permettant l'upload et le traitement des logs

---

### Phase 4 : CrÃ©ation des Interfaces Utilisateur

**Objectif** : Designer des interfaces modernes et intuitives avec HTML/CSS/JavaScript

#### Interface 1 : **Page d'Accueil / Dashboard Principal** (`/`)

**Description** :
- **En-tÃªte** : Logo LogStream Studio avec navigation vers toutes les pages
- **KPIs en temps rÃ©el** :
  - Total de logs dans Elasticsearch
  - Logs rÃ©cents (derniÃ¨res 24h basÃ© sur les donnÃ©es disponibles)
  - Nombre d'erreurs (status='failed')
  - Fichiers uploadÃ©s (depuis MongoDB)
- **Graphique Timeline** : Visualisation Chart.js des logs sur 30 derniers jours
- **Section Services** : Cards avec status de chaque service (Elasticsearch, Kibana, MongoDB, Redis, Logstash)
- **Design** : ThÃ¨me sombre moderne avec dÃ©gradÃ©s et animations

**FonctionnalitÃ©s** :
- RafraÃ®chissement automatique des stats toutes les 5 secondes
- Indicateurs visuels colorÃ©s (vert/rouge) pour les status
- Liens directs vers Kibana, Mongo Express, indices Elasticsearch
- Responsive design

#### Interface 2 : **Page d'Upload** (`/upload`)

**Description** :
- **Zone de drag & drop** : Interface intuitive pour glisser-dÃ©poser les fichiers
- **SÃ©lecteur de fichiers** : Bouton classique pour choisir un fichier
- **PrÃ©visualisation en temps rÃ©el** : Affichage des 10 premiÃ¨res lignes aprÃ¨s upload
- **MÃ©tadonnÃ©es** : 
  - Nom du fichier
  - Taille (Ko/Mo)
  - Type MIME
  - Date d'upload
  - Statut de traitement
- **Design** : Cards avec icÃ´nes, animations de transition, feedback visuel

**FonctionnalitÃ©s** :
- Validation cÃ´tÃ© client des extensions (.csv, .json, .txt, .log)
- Upload AJAX avec barre de progression
- Messages de succÃ¨s/erreur dynamiques
- Redirection automatique vers le dashboard aprÃ¨s succÃ¨s

#### Interface 3 : **Page Fichiers / Dashboard Uploads** (`/dashboard`)

**Description** :
- **Statistiques MongoDB** :
  - Total des uploads
  - Uploads rÃ©ussis
  - Uploads en erreur
- **Liste des 10 derniers uploads** :
  - Tableau avec colonnes : Nom, Taille, Type, Date, Statut
  - Badges colorÃ©s pour les statuts (vert=success, rouge=error)
  - IcÃ´nes selon le type de fichier
- **Design** : Layout en grille avec cards statistiques en haut

**FonctionnalitÃ©s** :
- Tri par date (plus rÃ©cent en premier)
- Affichage formatÃ© des tailles (Ko/Mo)
- Dates au format franÃ§ais
- Message si aucun upload

#### Interface 4 : **Page Health Check** (`/health`)

**Description** :
- **Status de chaque service** :
  - âœ… Elasticsearch (9200) - Connected/Disconnected + version
  - âœ… Kibana (5601) - Accessible/Inaccessible
  - âœ… MongoDB (27017) - Connected + nombre de documents
  - âœ… Redis (6379) - Connected + test PING
  - âœ… Logstash (9600) - Running + version
- **Informations systÃ¨me** :
  - Timestamp de vÃ©rification
  - Status global (All systems operational / Some issues)
- **Design** : Cards avec icÃ´nes de services, couleurs selon status

**FonctionnalitÃ©s** :
- VÃ©rification en temps rÃ©el au chargement
- Indicateurs visuels clairs (âœ…/âŒ)
- Liens vers les interfaces d'administration
- Bouton de rafraÃ®chissement

#### Interface 5 : **Page de Recherche** (`/search`)

**Description** :
- **Formulaire de recherche avancÃ©e** :
  - Champ texte libre (recherche multi-champs)
  - Filtre par niveau (status: success/failed)
  - Filtre par service/source
  - SÃ©lecteur de dates (de/Ã )
- **RÃ©sultats paginÃ©s** :
  - Affichage en cards avec highlights
  - 50 rÃ©sultats par page
  - Pagination avec boutons PrÃ©cÃ©dent/Suivant
- **DÃ©tails des logs** :
  - Timestamp, message, niveau, source
  - Champs additionnels (customer_name, payment_type, amount, etc.)
- **Design** : Interface de type moteur de recherche avec rÃ©sultats stylisÃ©s

**FonctionnalitÃ©s** :
- Recherche fuzzy (tolÃ©rance aux fautes)
- Multi-match sur plusieurs champs (message, product, customer_name, payment_type)
- Filtres combinables
- Export JSON des rÃ©sultats possible
- Highlighting des termes recherchÃ©s

#### Interface 6 : **Page de Connexion** (`/login`)

**Description** :
- **Formulaire centrÃ©** avec logo animÃ©
- **Champs** :
  - Nom d'utilisateur (icÃ´ne ğŸ‘¤)
  - Mot de passe (icÃ´ne ğŸ”’)
  - Checkbox "Se souvenir de moi"
- **Bouton de connexion** avec animation de chargement
- **Lien** vers la page d'inscription
- **Design** : Glassmorphism, fond avec dÃ©gradÃ©s animÃ©s, animations fluides

**FonctionnalitÃ©s** :
- Validation cÃ´tÃ© client
- Authentication JWT via API `/api/login`
- Cookie httpOnly avec expiration (24h ou 30j si "remember")
- Messages d'erreur clairs
- Auto-focus sur le champ username
- Redirection vers `/` aprÃ¨s connexion rÃ©ussie

#### Interface 7 : **Page d'Inscription** (`/signup`)

**Description** :
- **Formulaire d'inscription** :
  - Nom d'utilisateur (min 3 caractÃ¨res)
  - Email (validation format)
  - Mot de passe (min 6 caractÃ¨res)
  - Confirmation mot de passe
- **Validation en temps rÃ©el** :
  - VÃ©rification des longueurs minimales
  - Comparaison des mots de passe
  - Messages d'aide sous les champs
- **Lien** vers la page de connexion
- **Design** : MÃªme thÃ¨me que login avec logo vert

**FonctionnalitÃ©s** :
- CrÃ©ation de compte via API `/api/signup`
- Stockage dans MongoDB (collection `users`)
- Hash des mots de passe avec werkzeug.security
- VÃ©rification unicitÃ© username et email
- Redirection vers `/login` aprÃ¨s crÃ©ation rÃ©ussie
- Scroll vertical activÃ© pour voir tout le formulaire

**Technologies Frontend** :
- HTML5 sÃ©mantique
- CSS3 avec variables custom et animations
- Vanilla JavaScript (ES6+)
- Chart.js pour les graphiques
- Fetch API pour les requÃªtes AJAX
- Google Fonts (Inter)

---

### Phase 5 : SystÃ¨me d'Authentification JWT

**Objectif** : SÃ©curiser l'application avec authentification et gestion des utilisateurs

#### Ã‰tapes rÃ©alisÃ©es :

1. **Module d'Authentification** (`webapp/auth.py`)
   - Classe `AuthManager` pour gÃ©rer les tokens JWT
   - GÃ©nÃ©ration de tokens avec expiration (24h par dÃ©faut)
   - VÃ©rification des credentials (MongoDB + fallback admin)
   - Extraction des tokens depuis cookies ou headers
   - DÃ©corateurs `@login_required` et `@api_login_required`

2. **Gestion des Utilisateurs MongoDB**
   - Collection `users` avec schÃ©ma :
     ```python
     {
       'username': str,
       'email': str,
       'password_hash': str,  # Hash sÃ©curisÃ©
       'role': str,           # 'user' ou 'admin'
       'created_at': datetime,
       'last_login': datetime,
       'is_active': bool
     }
     ```
   - Fonction `create_user()` avec validations
   - Fonction `verify_credentials()` pour login
   - Mise Ã  jour automatique de `last_login`

3. **Routes API d'Authentification**
   - `POST /api/login` : Connexion avec JWT
   - `POST /api/signup` : CrÃ©ation de compte
   - `POST /api/logout` : DÃ©connexion (suppression cookie)
   - `GET /api/verify-token` : VÃ©rification de session

4. **Protection des Routes**
   - Toutes les pages principales protÃ©gÃ©es par `@login_required`
   - Routes API protÃ©gÃ©es par `@api_login_required`
   - Redirection automatique vers `/login` si non authentifiÃ©
   - Stockage des infos utilisateur dans `request.user`

5. **Configuration SÃ©curitÃ©**
   - Variables d'environnement pour JWT_SECRET_KEY
   - Cookies httpOnly pour Ã©viter XSS
   - Hash des mots de passe avec scrypt
   - Compte admin par dÃ©faut (admin/admin123) comme fallback

**RÃ©sultats** : Application entiÃ¨rement sÃ©curisÃ©e avec gestion multi-utilisateurs

---

### Phase 6 : Optimisation et Debugging

**Objectif** : RÃ©soudre les problÃ¨mes et optimiser les performances

#### ProblÃ¨mes rÃ©solus :

1. **Graphiques vides sur le dashboard**
   - **Cause** : DonnÃ©es datÃ©es de novembre 2025, requÃªtes cherchaient "aujourd'hui" (janvier 2026)
   - **Solution** : Modification de l'API `/api/stats` pour afficher toutes les donnÃ©es disponibles
   - Calcul dynamique des "logs rÃ©cents" basÃ© sur la date la plus rÃ©cente des donnÃ©es
   - Timeline affichant 30 derniers jours de donnÃ©es (au lieu de seulement 7j depuis maintenant)

2. **Inputs non cliquables sur login/signup**
   - **Cause** : `z-index` insuffisant sur `.login-card`
   - **Solution** : Ajout de `z-index: 100` pour passer au-dessus de la dÃ©coration de fond

3. **Scroll bloquÃ© sur signup**
   - **Cause** : `overflow: hidden` sur `.login-body`
   - **Solution** : Changement vers `overflow-y: auto` + `padding: 2rem 0`

4. **Services non accessibles**
   - **Cause** : Flask local utilisait hostnames Docker (mongodb, elasticsearch)
   - **Solution** : Configuration `.env` avec localhost pour tous les services
   - Modification de `app.py` pour charger les variables d'environnement

5. **Port Logstash manquant**
   - **Cause** : Port 9600 (API monitoring) non exposÃ© dans docker-compose
   - **Solution** : Ajout du mapping `9600:9600`

6. **Volume uploads non montÃ©**
   - **Cause** : Logstash ne voyait pas les fichiers uploadÃ©s
   - **Solution** : Ajout du volume `./data/uploads:/data/uploads:ro` dans docker-compose

**RÃ©sultats** : Application stable et performante sans bugs

---

### Phase 7 : Scripts Utilitaires

**Objectif** : Fournir des outils pour le dÃ©veloppement et le test

#### Scripts crÃ©Ã©s :

1. **`scripts/view-users.py`**
   - Affiche tous les utilisateurs de MongoDB
   - Statistiques (total, actifs, derniÃ¨re connexion)
   - Commandes utiles pour gÃ©rer les users

2. **`scripts/generate-recent-data.py`**
   - GÃ©nÃ¨re 500 transactions e-commerce avec dates rÃ©centes
   - Sortie CSV et JSON dans `/tmp/logstream_test_data/`
   - RÃ©partition 70% success / 30% failed
   - Utilisation : Tester la mise Ã  jour automatique des graphiques

3. **`scripts/setup-kibana-dashboard.sh`**
   - Automatise l'import des dashboards Kibana
   - Configure les visualisations e-commerce

4. **`scripts/inject-ecommerce-data.sh`**
   - Injecte les donnÃ©es de test dans Elasticsearch
   - 1000 transactions e-commerce initiales

**RÃ©sultats** : Outils facilitant le dÃ©veloppement et les tests

---

### Phase 8 : Nettoyage et Documentation

**Objectif** : Nettoyer le code et documenter le projet

#### Actions rÃ©alisÃ©es :

1. **Suppression des fichiers inutiles**
   - `example_app.py` (dÃ©mo non utilisÃ©e)
   - `quick_test.py` (script de test)
   - `test_database.py` (tests unitaires)
   - `test_es_stats.py` (diagnostic temporaire)
   - `.env.example` (doublon de .env)
   - `REORGANISATION.md` (historique, `ARCHITECTURE.md` suffit)

2. **Organisation des dossiers**
   - `config/` : Fichiers de configuration Kibana et donnÃ©es de test
   - `docs/` : Documentation technique (AUTH-SYSTEM.md, DESIGN.md, etc.)
   - `scripts/` : Scripts utilitaires Python et Bash
   - `data/` : Volumes Docker persistants
   - `pipeline/` : Configurations Logstash
   - `webapp/` : Application Flask complÃ¨te

3. **Documentation**
   - `README.md` : Guide complet (ce fichier)
   - `ARCHITECTURE.md` : Structure dÃ©taillÃ©e du projet
   - `docs/AUTH-SYSTEM.md` : Documentation systÃ¨me d'authentification
   - Commentaires dans le code

**RÃ©sultats** : Projet propre, organisÃ© et bien documentÃ©

---

## ğŸ“Š Statistiques du Projet

- **7 services Docker** orchestrÃ©s
- **8 pages web** interactives
- **15+ routes API** REST
- **2 bases de donnÃ©es** (MongoDB, Redis)
- **3 pipelines Logstash** (CSV, JSON, e-commerce)
- **1000+ documents** de test dans Elasticsearch
- **Authentification JWT** complÃ¨te
- **~3000 lignes de code** Python/HTML/CSS/JS

---

## ğŸ—ï¸ Architecture

Le projet est composÃ© de **7 services Docker** orchestrÃ©s via Docker Compose :

### Services Principaux

1. **Elasticsearch** (Port: 9200)
   - Moteur de recherche et d'analyse pour le stockage des logs
   - Configuration single-node pour le dÃ©veloppement
   - Persistance des donnÃ©es dans `./data/elasticsearch`

2. **Kibana** (Port: 5601)
   - Interface de visualisation des donnÃ©es Elasticsearch
   - Dashboard interactif pour l'analyse des logs
   - Persistance dans `./data/kibana`

3. **Logstash** (Port: 5044)
   - Pipeline de traitement des logs (CSV et JSON)
   - Configurations personnalisÃ©es dans `./pipeline`
   - Ingestion automatique des fichiers uploadÃ©s

4. **MongoDB** (Port: 27017)
   - Base de donnÃ©es NoSQL pour les mÃ©tadonnÃ©es des fichiers
   - Stockage des informations d'upload
   - Persistance dans `./data/mongodb`

5. **Mongo Express** (Port: 8081)
   - Interface web d'administration pour MongoDB
   - Visualisation et gestion des bases de donnÃ©es
   - Authentification : admin / admin123

6. **Redis** (Port: 6379)
   - Cache en mÃ©moire pour les sessions et donnÃ©es temporaires
   - Persistance dans `./data/redis`

7. **WebApp Flask** (Port: 8000)
   - Interface web pour le tÃ©lÃ©chargement de fichiers
   - API REST pour l'upload de logs
   - Gestion des mÃ©tadonnÃ©es et prÃ©visualisation

## ğŸ“ Structure du Projet

```
projet/
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ README.md                   # Documentation principale
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ .env.example                # Template de configuration
â”œâ”€â”€ .gitignore                  # Fichiers ignorÃ©s par Git
â”‚
â”œâ”€â”€ config/                     # ğŸ“‹ Fichiers de configuration
â”‚   â”œâ”€â”€ dashboard-final.ndjson         # Dashboard Kibana final
â”‚   â”œâ”€â”€ ecommerce-dashboard-export.ndjson
â”‚   â”œâ”€â”€ fix-tables.ndjson             # Configuration des tables
â”‚   â”œâ”€â”€ fix-visualizations.ndjson     # Configuration des visualisations
â”‚   â”œâ”€â”€ kibana-import-pro.ndjson      # Import Kibana professionnel
â”‚   â”œâ”€â”€ kibana-import.ndjson          # Import Kibana basique
â”‚   â”œâ”€â”€ test-ecommerce-logs.json      # Logs de test e-commerce
â”‚   â””â”€â”€ test-mongo.csv                # DonnÃ©es de test MongoDB
â”‚
â”œâ”€â”€ data/                       # ğŸ’¾ DonnÃ©es persistantes (volumes Docker)
â”‚   â”œâ”€â”€ elasticsearch/          # Index Elasticsearch
â”‚   â”œâ”€â”€ kibana/                 # Configuration Kibana
â”‚   â”œâ”€â”€ logstash/               # DonnÃ©es Logstash
â”‚   â”œâ”€â”€ mongodb/                # Base MongoDB
â”‚   â”œâ”€â”€ redis/                  # Snapshots Redis
â”‚   â””â”€â”€ uploads/                # Fichiers uploadÃ©s
â”‚
â”œâ”€â”€ docs/                       # ğŸ“š Documentation complÃ¨te
â”‚   â”œâ”€â”€ AUTH-SYSTEM.md          # SystÃ¨me d'authentification JWT
â”‚   â”œâ”€â”€ CHANGELOG-AUTH.md       # Changelog authentification
â”‚   â”œâ”€â”€ CHANGELOG-DASHBOARD.md  # Changelog dashboard
â”‚   â”œâ”€â”€ CREDENTIALS.md          # Identifiants et accÃ¨s
â”‚   â”œâ”€â”€ DATABASE-MODULE.md      # Module base de donnÃ©es
â”‚   â”œâ”€â”€ DARK-THEME.md           # Guide du thÃ¨me dark
â”‚   â”œâ”€â”€ DESIGN.md               # Design system
â”‚   â”œâ”€â”€ KIBANA-DASHBOARD.md     # Documentation Kibana
â”‚   â”œâ”€â”€ PHASE5-COMPLETE.md      # Historique Phase 5
â”‚   â”œâ”€â”€ RECAP-AUTH.md           # RÃ©capitulatif authentification
â”‚   â””â”€â”€ SEARCH-PAGE.md          # Page de recherche
â”‚
â”œâ”€â”€ elasticsearch/              # âš™ï¸ Configuration Elasticsearch
â”‚   â””â”€â”€ logs-saas-template.json # Template d'index
â”‚
â”œâ”€â”€ pipeline/                   # ğŸ”„ Pipelines Logstash
â”‚   â”œâ”€â”€ csv-pipeline.conf       # Pipeline pour fichiers CSV
â”‚   â””â”€â”€ json-pipeline.conf      # Pipeline pour fichiers JSON
â”‚
â”œâ”€â”€ scripts/                    # ğŸ”§ Scripts utilitaires
â”‚   â”œâ”€â”€ add-service-logs.py            # Ajout de logs de services
â”‚   â”œâ”€â”€ fill-empty-fields.py           # Remplissage des champs vides
â”‚   â”œâ”€â”€ fix-kibana-dashboard.sh        # Correction dashboard Kibana
â”‚   â”œâ”€â”€ inject-ecommerce-data.sh       # Injection donnÃ©es e-commerce
â”‚   â”œâ”€â”€ inject-service-logs.py         # Injection logs de services
â”‚   â”œâ”€â”€ regenerate-customer-data.sh    # RÃ©gÃ©nÃ©ration donnÃ©es clients
â”‚   â”œâ”€â”€ setup-kibana-dashboard.sh      # Configuration dashboard
â”‚   â”œâ”€â”€ test-auth-system.py            # Tests authentification
â”‚   â”œâ”€â”€ test-services.sh               # Tests des services
â”‚   â”œâ”€â”€ update-logs-service.py         # Mise Ã  jour logs
â”‚   â””â”€â”€ verify-kibana-setup.sh         # VÃ©rification setup Kibana
â”‚
â””â”€â”€ webapp/                     # ğŸŒ Application Web Flask
    â”œâ”€â”€ app.py                  # Application Flask principale
    â”œâ”€â”€ auth.py                 # Module d'authentification JWT
    â”œâ”€â”€ database.py             # Module base de donnÃ©es
    â”œâ”€â”€ Dockerfile              # Image Docker
    â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
    â”œâ”€â”€ models/                 # ModÃ¨les de donnÃ©es
    â”‚   â””â”€â”€ __init__.py
    â”œâ”€â”€ routes/                 # Routes API
    â”‚   â””â”€â”€ __init__.py
    â”œâ”€â”€ static/                 # Ressources statiques
    â”‚   â””â”€â”€ style.css           # Stylesheet principal
    â”œâ”€â”€ templates/              # Templates HTML
    â”‚   â”œâ”€â”€ index.html          # Dashboard principal
    â”‚   â”œâ”€â”€ login.html          # Page de connexion
    â”‚   â”œâ”€â”€ upload.html         # Page d'upload
    â”‚   â”œâ”€â”€ dashboard.html      # Dashboard monitoring
    â”‚   â”œâ”€â”€ health.html         # Health check
    â”‚   â””â”€â”€ search.html         # Recherche de logs
    â”œâ”€â”€ uploads/                # (deprecated)
    â””â”€â”€ utils/                  # Utilitaires
```

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis

- Docker (version 20.10+)
- Docker Compose (version 1.29+)
- 4 GB RAM minimum disponible pour Docker

### Variables d'Environnement

CrÃ©ez un fichier `.env` Ã  la racine du projet avec les valeurs suivantes :

```bash
# Versions ELK Stack
ELASTIC_VERSION=8.10.0
KIBANA_VERSION=8.10.0
LOGSTASH_VERSION=8.10.0

# Flask Configuration
FLASK_ENV=development
FLASK_RUN_PORT=8000
```

### DÃ©marrage des Services

1. **Cloner le projet** (si nÃ©cessaire)
```bash
cd /home/dorrah/Bureau/projet
```

2. **CrÃ©er le fichier .env**
```bash
cat > .env << EOF
ELASTIC_VERSION=8.10.0
KIBANA_VERSION=8.10.0
LOGSTASH_VERSION=8.10.0
FLASK_ENV=development
FLASK_RUN_PORT=8000
EOF
```

3. **Lancer tous les services**
```bash
docker-compose up -d
```

4. **VÃ©rifier l'Ã©tat des services**
```bash
docker-compose ps
```

5. **Consulter les logs** (optionnel)
```bash
docker-compose logs -f
```

### ArrÃªt des Services

```bash
docker-compose down
```

Pour supprimer Ã©galement les volumes de donnÃ©es :
```bash
docker-compose down -v
```

## ğŸ” Authentification et SÃ©curitÃ©

### SystÃ¨me d'authentification JWT

LogStream Studio intÃ¨gre un systÃ¨me d'authentification sÃ©curisÃ© basÃ© sur **JWT (JSON Web Tokens)** pour protÃ©ger l'accÃ¨s Ã  l'interface d'administration.

#### ğŸ”‘ Identifiants par dÃ©faut
- **Username**: `admin`
- **Password**: `admin123`

âš ï¸ **Important**: Changez ces identifiants en production via les variables d'environnement.

#### Configuration dans `.env`

```dotenv
# Authentication
JWT_SECRET_KEY=your-secret-key-change-this-in-production
JWT_EXPIRATION_HOURS=24
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
```

#### FonctionnalitÃ©s
- âœ… Authentification par JWT avec cookies HTTP-only
- âœ… Expiration automatique des tokens (24h par dÃ©faut)
- âœ… Option "Se souvenir de moi" (30 jours)
- âœ… Protection contre XSS et CSRF
- âœ… Hachage sÃ©curisÃ© des mots de passe (PBKDF2-SHA256)
- âœ… Toutes les routes principales protÃ©gÃ©es

#### Routes protÃ©gÃ©es
- `/` - Dashboard principal
- `/health` - Health check
- `/search` - Recherche de logs
- `/upload` - Upload de fichiers
- `/dashboard` - Dashboard de monitoring
- Toutes les routes `/api/*` (sauf login/logout)

#### Documentation complÃ¨te
ğŸ“– Consultez [AUTH-SYSTEM.md](./AUTH-SYSTEM.md) pour la documentation dÃ©taillÃ©e du systÃ¨me d'authentification.

## ğŸ¨ Interface Web Moderne - Dark Theme

L'application dispose d'une interface web professionnelle en **mode dark** avec :

- **ğŸ  Page d'Accueil** : Vue d'ensemble des services et fonctionnalitÃ©s
- **ğŸ“¤ Page Upload** : Interface drag & drop pour uploader des fichiers
- **ğŸ“Š Dashboard** : Statistiques et liste des uploads rÃ©cents
- **ğŸŒ™ ThÃ¨me Dark** : Palette sombre Ã©lÃ©gante (Slate) avec effets glow
- **ğŸ¯ Design moderne** : Cards Ã©levÃ©es, animations fluides, contraste optimal
- **ğŸ“± Responsive** : S'adapte Ã  tous les Ã©crans

ğŸ“„ **Documentation design** :
- [DESIGN.md](./DESIGN.md) - Guide complet du design system
- [DARK-THEME.md](./DARK-THEME.md) - DÃ©tails du thÃ¨me dark et palette

## ğŸ”— Liens de Test et AccÃ¨s aux Services

### ğŸ“‹ Tableau RÃ©capitulatif des AccÃ¨s

| Service | URL | Port | Authentification |
|---------|-----|------|------------------|
| **Flask WebApp** | http://localhost:8000 | 8000 | **admin / admin123** |
| **Kibana** | http://localhost:5601 | 5601 | Aucune |
| **Mongo Express** | http://localhost:8081 | 8081 | admin / admin123 |
| **Elasticsearch** | http://localhost:9200 | 9200 | Aucune |
| **MongoDB** | localhost:27017 | 27017 | Aucune |
| **Redis** | localhost:6379 | 6379 | Aucune |
| **Logstash** | - | 5044 | - |

### ğŸŒ Application Web Flask
- **URL principale** : http://localhost:8000
- **Page d'upload** : http://localhost:8000/upload
- **Description** : Interface pour tÃ©lÃ©charger des fichiers CSV/JSON

### ğŸ“Š Kibana (Visualisation)
- **URL** : http://localhost:5601
- **Usage** : 
  - AccÃ©dez Ã  "Discover" pour explorer les logs
  - CrÃ©ez des visualisations et dashboards
  - Index patterns Ã  configurer : `logs-saas-csv*` et `logs-saas-json*`

### ğŸ” Elasticsearch (API)
- **URL** : http://localhost:9200
- **Health check** : http://localhost:9200/_cluster/health
- **Liste des index** : http://localhost:9200/_cat/indices?v
- **Recherche logs CSV** : http://localhost:9200/logs-saas-csv/_search
- **Recherche logs JSON** : http://localhost:9200/logs-saas-json/_search

### ğŸ’¾ MongoDB (Base de donnÃ©es)
- **Host** : localhost:27017
- **Connexion via CLI** :
```bash
docker exec -it mongodb mongosh
```
- **Commandes utiles** :
```javascript
use monitoring
db.uploads.find().pretty()  // Voir les mÃ©tadonnÃ©es des uploads
```

### ğŸ—„ï¸ Mongo Express (Interface MongoDB)
- **URL** : http://localhost:8081
- **Authentification** :
  - Username : `admin`
  - Password : `admin123`
- **FonctionnalitÃ©s** :
  - âœ… Visualiser toutes les bases de donnÃ©es MongoDB
  - âœ… Parcourir la collection `monitoring.uploads`
  - âœ… CrÃ©er/modifier/supprimer des documents
  - âœ… Exporter des donnÃ©es en JSON/CSV
  - âœ… ExÃ©cuter des requÃªtes MongoDB
  - âœ… Gestion des index

**Guide d'utilisation rapide** :
1. Ouvrez http://localhost:8081 dans votre navigateur
2. Entrez les identifiants : `admin` / `admin123`
3. Cliquez sur la base de donnÃ©es `monitoring`
4. SÃ©lectionnez la collection `uploads`
5. Visualisez les mÃ©tadonnÃ©es des fichiers uploadÃ©s

### ğŸ”´ Redis (Cache)
- **Host** : localhost:6379
- **Connexion via CLI** :
```bash
docker exec -it redis redis-cli
```

### ğŸ“¥ Logstash (Pipeline)
- **Port** : 5044
- **Logs en temps rÃ©el** :
```bash
docker logs -f logstash
```

## ğŸ“¤ Utilisation - Upload de Fichiers

### Via l'Interface Web

1. AccÃ©dez Ã  http://localhost:8000/upload
2. SÃ©lectionnez un fichier CSV ou JSON
3. Cliquez sur "Upload"
4. Visualisez la prÃ©visualisation des donnÃ©es

### Via API (cURL)

**Upload d'un fichier CSV :**
```bash
curl -X POST -F "file=@votre_fichier.csv" http://localhost:8000/upload
```

**Upload d'un fichier JSON :**
```bash
curl -X POST -F "file=@votre_fichier.json" http://localhost:8000/upload
```

### Formats de Fichiers SupportÃ©s

#### CSV
```csv
timestamp,level,message
2024-01-01T10:00:00Z,INFO,Application started
2024-01-01T10:05:00Z,ERROR,Connection failed
```

#### JSON
```json
{"timestamp": "2024-01-01T10:00:00Z", "level": "INFO", "message": "Application started"}
{"timestamp": "2024-01-01T10:05:00Z", "level": "ERROR", "message": "Connection failed"}
```

## ğŸ”„ Pipeline de Traitement des Logs

### Workflow

1. **Upload** â†’ Fichier tÃ©lÃ©chargÃ© via Flask (`/upload`)
2. **Sauvegarde** â†’ StockÃ© dans `./data/uploads/`
3. **MÃ©tadonnÃ©es** â†’ EnregistrÃ©es dans MongoDB (collection `uploads`)
4. **Traitement** â†’ Logstash dÃ©tecte et parse le fichier
5. **Indexation** â†’ Les logs sont envoyÃ©s vers Elasticsearch
6. **Visualisation** â†’ DonnÃ©es disponibles dans Kibana

### Pipelines Logstash

- **CSV Pipeline** : Parse les fichiers `.csv` â†’ Index `logs-saas-csv`
- **JSON Pipeline** : Parse les fichiers `.json` â†’ Index `logs-saas-json`

## ğŸ“Š Configuration Kibana

### PremiÃ¨re Configuration

1. AccÃ©dez Ã  http://localhost:5601
2. Allez dans **Stack Management** â†’ **Index Patterns**
3. CrÃ©ez un index pattern :
   - Pattern name : `logs-saas-*`
   - Time field : `@timestamp`
4. AccÃ©dez Ã  **Discover** pour explorer vos logs

### CrÃ©ation de Visualisations

- **Management** â†’ **Visualize Library** â†’ **Create visualization**
- Types disponibles : Line chart, Bar chart, Pie chart, Data table, etc.

## ğŸ› ï¸ DÃ©pannage

### âš ï¸ ProblÃ¨me de Permissions (Erreur EACCES ou AccessDeniedException)

**SymptÃ´mes** : Elasticsearch ou Kibana redÃ©marrent en boucle avec des erreurs de permissions

**Solution** :
```bash
# ArrÃªter tous les services
docker compose down

# Corriger les permissions des dossiers de donnÃ©es
sudo chmod -R 777 data/

# Ou recrÃ©er les dossiers si nÃ©cessaire
sudo rm -rf data/elasticsearch data/kibana data/logstash
sudo mkdir -p data/elasticsearch data/kibana data/logstash data/uploads
sudo chmod -R 777 data/

# RedÃ©marrer les services
docker compose up -d
```

### Les services ne dÃ©marrent pas

```bash
# VÃ©rifier les logs
docker compose logs

# VÃ©rifier l'Ã©tat des services
docker compose ps

# RedÃ©marrer un service spÃ©cifique
docker compose restart webapp
docker compose restart elasticsearch
```

### Elasticsearch ne dÃ©marre pas (mÃ©moire insuffisante)

Ajustez les paramÃ¨tres Java dans `docker-compose.yml` :
```yaml
ES_JAVA_OPTS=-Xms256m -Xmx256m  # RÃ©duit de 512m Ã  256m
```

### Kibana en boucle de redÃ©marrage

1. **VÃ©rifier les logs** :
```bash
docker logs kibana --tail 50
```

2. **Si erreur de permissions**, suivre la solution ci-dessus

3. **Attendre qu'Elasticsearch soit prÃªt** (peut prendre 30-60 secondes au dÃ©marrage)

### Les fichiers uploadÃ©s ne sont pas traitÃ©s

1. VÃ©rifiez que Logstash est dÃ©marrÃ© :
```bash
docker compose ps logstash
```

2. Consultez les logs Logstash :
```bash
docker logs -f logstash
```

3. VÃ©rifiez que les fichiers sont dans `./data/uploads/`

### MongoDB n'est pas accessible

```bash
# RedÃ©marrer MongoDB
docker compose restart mongodb

# VÃ©rifier les logs
docker logs mongodb
```

## ğŸ§ª Tests et Validation

### âš¡ Test Rapide de Tous les Services

Utilisez le script de test automatisÃ© :

```bash
./test-services.sh
```

Ce script vÃ©rifie automatiquement :
- âœ… AccessibilitÃ© de tous les services web
- âœ… Ã‰tat des APIs (Elasticsearch, Flask)
- âœ… Connexion MongoDB et Redis
- âœ… Ã‰tat des conteneurs Docker

### Test Complet du Workflow

1. **CrÃ©er un fichier de test** :
```bash
cat > test.csv << EOF
timestamp,level,message
2024-11-08T10:00:00Z,INFO,Test log 1
2024-11-08T10:01:00Z,WARN,Test log 2
2024-11-08T10:02:00Z,ERROR,Test log 3
EOF
```

2. **Upload le fichier** :
```bash
curl -X POST -F "file=@test.csv" http://localhost:8000/upload
```

3. **VÃ©rifier dans MongoDB** (2 options) :

**Via CLI** :
```bash
docker exec -it mongodb mongosh --eval "use monitoring; db.uploads.find().pretty()"
```

**Via Mongo Express** :
- Ouvrez http://localhost:8081
- Connectez-vous avec `admin` / `admin123`
- Naviguez vers la base `monitoring` â†’ collection `uploads`
- Visualisez les mÃ©tadonnÃ©es du fichier uploadÃ©

4. **Attendre 10-30 secondes** pour le traitement Logstash

5. **VÃ©rifier dans Elasticsearch** :
```bash
curl http://localhost:9200/logs-saas-csv/_search?pretty
```

6. **Visualiser dans Kibana** : http://localhost:5601

## ğŸ“ˆ Monitoring et MÃ©triques

### Health Checks

```bash
# Elasticsearch
curl http://localhost:9200/_cluster/health?pretty

# Webapp Flask
curl http://localhost:8000


# Kibana
curl http://localhost:5601/api/status
```

### Statistiques des Index

```bash
# Nombre de documents par index
curl http://localhost:9200/_cat/count/logs-saas-*?v

# Taille des index
curl http://localhost:9200/_cat/indices/logs-saas-*?v&s=store.size:desc
```

## ğŸ” SÃ©curitÃ©

âš ï¸ **Note de sÃ©curitÃ©** : Cette configuration est prÃ©vue pour le **dÃ©veloppement uniquement**.

### Identifiants par DÃ©faut

ğŸ“„ Consultez le fichier **[CREDENTIALS.md](./CREDENTIALS.md)** pour la liste complÃ¨te des identifiants.

**AccÃ¨s rapide** :
- Mongo Express : `admin` / `admin123`
- Autres services : Authentification dÃ©sactivÃ©e en mode dÃ©veloppement

### Pour la Production

Activez impÃ©rativement :
- âœ… L'authentification Elasticsearch/Kibana (X-Pack Security)
- âœ… HTTPS/TLS pour tous les services
- âœ… Variables d'environnement sÃ©curisÃ©es (Docker Secrets)
- âœ… Authentification MongoDB avec utilisateurs dÃ©diÃ©s
- âœ… Mot de passe Redis
- âœ… Rate limiting sur l'API Flask
- âœ… Changez tous les mots de passe par dÃ©faut

## ğŸ“ Technologies UtilisÃ©es

- **Python 3.11** - Application Flask
- **Flask 2.3.2** - Framework web
- **Elasticsearch 8.10.3** - Moteur de recherche
- **Kibana 8.10.3** - Visualisation des logs
- **Logstash 8.10.3** - Pipeline de traitement
- **MongoDB 7** - Base de donnÃ©es NoSQL
- **Mongo Express 1.0.2** - Interface d'administration MongoDB
- **Redis 7** - Cache en mÃ©moire
- **PyMongo 4.3.3** - Driver MongoDB pour Python
- **redis-py 4.5.1** - Client Redis pour Python
- **Docker & Docker Compose** - Conteneurisation et orchestration

## ğŸ—„ï¸ Module Database - IntÃ©gration MongoDB et Redis

### ğŸ“¦ Nouveau Module `database.py`

Un module Python centralisÃ© pour gÃ©rer les connexions MongoDB et Redis avec :

âœ… **Connexions automatiques** avec variables d'environnement
âœ… **Tests de connexion** au dÃ©marrage
âœ… **Health check** complet des services
âœ… **Gestion des erreurs** avec fallback gracieux
âœ… **API simple** pour rÃ©cupÃ©rer les clients

### ğŸš€ Utilisation Rapide

```python
from database import init_databases, db_manager

# Initialiser les connexions
init_databases()

# Utiliser MongoDB
uploads_col = db_manager.get_mongo_collection('uploads')
uploads_col.insert_one({'filename': 'test.csv', 'status': 'processed'})

# Utiliser Redis
redis_client = db_manager.get_redis_client()
redis_client.set('cache:key', 'value', ex=60)

# Health check
health = db_manager.health_check()
print(health)
```

### ğŸ§ª Tests Complets

Testez le module avec la suite de tests :

```bash
# Test basique
docker exec webapp python3 database.py

# Test complet (CRUD, Performance, Health Check)
docker exec webapp python3 test_database.py
```

**RÃ©sultats des tests** :
- âœ… MongoDB CRUD operations (71,361 ops/sec)
- âœ… Redis operations (33,127 SET/sec, 45,250 GET/sec)
- âœ… Health check avec mÃ©triques dÃ©taillÃ©es
- âœ… 100% de rÃ©ussite sur 4 catÃ©gories de tests

### ğŸ“š Documentation ComplÃ¨te

Consultez **[DATABASE-MODULE.md](./DATABASE-MODULE.md)** pour :
- Guide d'utilisation dÃ©taillÃ©
- API Reference complÃ¨te
- Variables d'environnement
- Exemples avancÃ©s (cache, bulk operations)
- DÃ©pannage et bonnes pratiques

### ğŸ”§ Configuration

Variables d'environnement disponibles dans `.env.example` :

```bash
# MongoDB
MONGO_URI=mongodb://mongodb:27017
MONGO_DB=monitoring
MONGO_TIMEOUT=5000

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_TIMEOUT=5
```

### ğŸ“Š MÃ©triques Health Check

Le module fournit des mÃ©triques dÃ©taillÃ©es :

```json
{
  "timestamp": "2025-11-25T16:29:15.663079",
  "services": {
    "mongodb": {
      "status": "healthy",
      "database": "monitoring",
      "collections": 2,
      "data_size_mb": 0.01
    },
    "redis": {
      "status": "healthy",
      "version": "7.4.7",
      "used_memory": "1.20M",
      "connected_clients": 1
    }
  }
}
```

## ğŸ¯ Cas d'Usage et Exemples

### Visualiser les MÃ©tadonnÃ©es dans Mongo Express

1. **AccÃ¨s** : http://localhost:8081 (admin / admin123)
2. **Navigation** : Base `monitoring` â†’ Collection `uploads`
3. **Visualisation** : Liste de tous les fichiers uploadÃ©s avec leurs mÃ©tadonnÃ©es

### RequÃªtes MongoDB Utiles

```javascript
// Compter tous les uploads
db.uploads.countDocuments()

// Trouver les uploads en erreur
db.uploads.find({status: "error"})

// Statistiques par extension
db.uploads.aggregate([
  { $group: { _id: "$extension", count: { $sum: 1 } } }
])

// Uploads des derniÃ¨res 24h
db.uploads.find({
  uploaded_at: { $gte: new Date(Date.now() - 24*60*60*1000).toISOString() }
})
```

### Pipeline ELK Complet

1. **Upload** â†’ Flask enregistre le fichier et les mÃ©tadonnÃ©es
2. **Stockage** â†’ Fichier dans `data/uploads/`, mÃ©tadonnÃ©es dans MongoDB
3. **Traitement** â†’ Logstash parse et transforme les logs
4. **Indexation** â†’ Elasticsearch stocke les logs indexÃ©s
5. **Visualisation** â†’ Kibana pour l'analyse, Mongo Express pour les mÃ©tadonnÃ©es

## ğŸ‘¥ Auteurs

Projet rÃ©alisÃ© dans le cadre du cours de Monitoring et ELK Stack.

## ğŸ“… Date

25 novembre 2025

---

**Bon monitoring ! ğŸ“ŠğŸš€**
