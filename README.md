# ğŸ“Š Monitoring SaaS - ELK Stack

## ğŸ“‹ Description du Projet

Ce projet est une plateforme de monitoring SaaS basÃ©e sur la stack ELK (Elasticsearch, Logstash, Kibana) intÃ©grÃ©e avec MongoDB, Redis et une application web Flask. La solution permet de tÃ©lÃ©charger, traiter et visualiser des fichiers de logs au format CSV et JSON.

## ğŸ—ï¸ Architecture

Le projet est composÃ© de **7 services Docker** orchestrÃ©s via Docker Compose :

### Services Principaux

1. **Elasticsearch** (Port: 9200)
   - Moteur de recherche et d'analyse pour le stockage des logs
   - Configuration single-node pour le dÃ©veloppement
   - Persistance des donnÃ©es dans `./data/elasticsearch`

2. **Kibana** (Port: 5601)
   - Interface de visualisation des donnÃ©es Elasticsearch
   - Dashboard interactif pour l'analyse des logs
   - Persistance dans `./data/kibana`

3. **Logstash** (Port: 5044)
   - Pipeline de traitement des logs (CSV et JSON)
   - Configurations personnalisÃ©es dans `./pipeline`
   - Ingestion automatique des fichiers uploadÃ©s

4. **MongoDB** (Port: 27017)
   - Base de donnÃ©es NoSQL pour les mÃ©tadonnÃ©es des fichiers
   - Stockage des informations d'upload
   - Persistance dans `./data/mongodb`

5. **Mongo Express** (Port: 8081)
   - Interface web d'administration pour MongoDB
   - Visualisation et gestion des bases de donnÃ©es
   - Authentification : admin / admin123

6. **Redis** (Port: 6379)
   - Cache en mÃ©moire pour les sessions et donnÃ©es temporaires
   - Persistance dans `./data/redis`

7. **WebApp Flask** (Port: 8000)
   - Interface web pour le tÃ©lÃ©chargement de fichiers
   - API REST pour l'upload de logs
   - Gestion des mÃ©tadonnÃ©es et prÃ©visualisation

## ğŸ“ Structure du Projet

```
projet/
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ README.md                   # Documentation (ce fichier)
â”œâ”€â”€ CREDENTIALS.md              # Identifiants et accÃ¨s
â”œâ”€â”€ DESIGN.md                   # Documentation du design system
â”œâ”€â”€ DARK-THEME.md               # Guide du thÃ¨me dark
â”œâ”€â”€ test-services.sh            # Script de test automatique
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ data/                       # DonnÃ©es persistantes
â”‚   â”œâ”€â”€ elasticsearch/          # Index Elasticsearch
â”‚   â”œâ”€â”€ kibana/                 # Config Kibana
â”‚   â”œâ”€â”€ logstash/               # Data Logstash
â”‚   â”œâ”€â”€ mongodb/                # Base MongoDB
â”‚   â”œâ”€â”€ redis/                  # Snapshots Redis
â”‚   â””â”€â”€ uploads/                # Fichiers uploadÃ©s
â”œâ”€â”€ elasticsearch/
â”‚   â””â”€â”€ logs-saas-template.json # Template d'index
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ csv-pipeline.conf       # Pipeline Logstash CSV
â”‚   â””â”€â”€ json-pipeline.conf      # Pipeline Logstash JSON
â””â”€â”€ webapp/
    â”œâ”€â”€ app.py                  # Application Flask (+ routes)
    â”œâ”€â”€ Dockerfile              # Image Docker webapp
    â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
    â”œâ”€â”€ templates/              # Templates HTML
    â”‚   â”œâ”€â”€ index.html          # Page d'accueil moderne
    â”‚   â”œâ”€â”€ upload.html         # Page d'upload avec drag & drop
    â”‚   â””â”€â”€ dashboard.html      # Dashboard avec statistiques
    â”œâ”€â”€ static/                 # Ressources statiques
    â”‚   â””â”€â”€ style.css           # Design system complet
    â””â”€â”€ uploads/                # (deprecated, use data/uploads)
```

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis

- Docker (version 20.10+)
- Docker Compose (version 1.29+)
- 4 GB RAM minimum disponible pour Docker

### Variables d'Environnement

CrÃ©ez un fichier `.env` Ã  la racine du projet avec les valeurs suivantes :

```bash
# Versions ELK Stack
ELASTIC_VERSION=8.10.0
KIBANA_VERSION=8.10.0
LOGSTASH_VERSION=8.10.0

# Flask Configuration
FLASK_ENV=development
FLASK_RUN_PORT=8000
```

### DÃ©marrage des Services

1. **Cloner le projet** (si nÃ©cessaire)
```bash
cd /home/dorrah/Bureau/projet
```

2. **CrÃ©er le fichier .env**
```bash
cat > .env << EOF
ELASTIC_VERSION=8.10.0
KIBANA_VERSION=8.10.0
LOGSTASH_VERSION=8.10.0
FLASK_ENV=development
FLASK_RUN_PORT=8000
EOF
```

3. **Lancer tous les services**
```bash
docker-compose up -d
```

4. **VÃ©rifier l'Ã©tat des services**
```bash
docker-compose ps
```

5. **Consulter les logs** (optionnel)
```bash
docker-compose logs -f
```

### ArrÃªt des Services

```bash
docker-compose down
```

Pour supprimer Ã©galement les volumes de donnÃ©es :
```bash
docker-compose down -v
```

## ğŸ¨ Interface Web Moderne - Dark Theme

L'application dispose d'une interface web professionnelle en **mode dark** avec :

- **ğŸ  Page d'Accueil** : Vue d'ensemble des services et fonctionnalitÃ©s
- **ğŸ“¤ Page Upload** : Interface drag & drop pour uploader des fichiers
- **ğŸ“Š Dashboard** : Statistiques et liste des uploads rÃ©cents
- **ğŸŒ™ ThÃ¨me Dark** : Palette sombre Ã©lÃ©gante (Slate) avec effets glow
- **ğŸ¯ Design moderne** : Cards Ã©levÃ©es, animations fluides, contraste optimal
- **ğŸ“± Responsive** : S'adapte Ã  tous les Ã©crans

ğŸ“„ **Documentation design** :
- [DESIGN.md](./DESIGN.md) - Guide complet du design system
- [DARK-THEME.md](./DARK-THEME.md) - DÃ©tails du thÃ¨me dark et palette

## ğŸ”— Liens de Test et AccÃ¨s aux Services

### ğŸ“‹ Tableau RÃ©capitulatif des AccÃ¨s

| Service | URL | Port | Authentification |
|---------|-----|------|------------------|
| **Flask WebApp** | http://localhost:8000 | 8000 | Aucune |
| **Kibana** | http://localhost:5601 | 5601 | Aucune |
| **Mongo Express** | http://localhost:8081 | 8081 | admin / admin123 |
| **Elasticsearch** | http://localhost:9200 | 9200 | Aucune |
| **MongoDB** | localhost:27017 | 27017 | Aucune |
| **Redis** | localhost:6379 | 6379 | Aucune |
| **Logstash** | - | 5044 | - |

### ğŸŒ Application Web Flask
- **URL principale** : http://localhost:8000
- **Page d'upload** : http://localhost:8000/upload
- **Description** : Interface pour tÃ©lÃ©charger des fichiers CSV/JSON

### ğŸ“Š Kibana (Visualisation)
- **URL** : http://localhost:5601
- **Usage** : 
  - AccÃ©dez Ã  "Discover" pour explorer les logs
  - CrÃ©ez des visualisations et dashboards
  - Index patterns Ã  configurer : `logs-saas-csv*` et `logs-saas-json*`

### ğŸ” Elasticsearch (API)
- **URL** : http://localhost:9200
- **Health check** : http://localhost:9200/_cluster/health
- **Liste des index** : http://localhost:9200/_cat/indices?v
- **Recherche logs CSV** : http://localhost:9200/logs-saas-csv/_search
- **Recherche logs JSON** : http://localhost:9200/logs-saas-json/_search

### ğŸ’¾ MongoDB (Base de donnÃ©es)
- **Host** : localhost:27017
- **Connexion via CLI** :
```bash
docker exec -it mongodb mongosh
```
- **Commandes utiles** :
```javascript
use monitoring
db.uploads.find().pretty()  // Voir les mÃ©tadonnÃ©es des uploads
```

### ğŸ—„ï¸ Mongo Express (Interface MongoDB)
- **URL** : http://localhost:8081
- **Authentification** :
  - Username : `admin`
  - Password : `admin123`
- **FonctionnalitÃ©s** :
  - âœ… Visualiser toutes les bases de donnÃ©es MongoDB
  - âœ… Parcourir la collection `monitoring.uploads`
  - âœ… CrÃ©er/modifier/supprimer des documents
  - âœ… Exporter des donnÃ©es en JSON/CSV
  - âœ… ExÃ©cuter des requÃªtes MongoDB
  - âœ… Gestion des index

**Guide d'utilisation rapide** :
1. Ouvrez http://localhost:8081 dans votre navigateur
2. Entrez les identifiants : `admin` / `admin123`
3. Cliquez sur la base de donnÃ©es `monitoring`
4. SÃ©lectionnez la collection `uploads`
5. Visualisez les mÃ©tadonnÃ©es des fichiers uploadÃ©s

### ğŸ”´ Redis (Cache)
- **Host** : localhost:6379
- **Connexion via CLI** :
```bash
docker exec -it redis redis-cli
```

### ğŸ“¥ Logstash (Pipeline)
- **Port** : 5044
- **Logs en temps rÃ©el** :
```bash
docker logs -f logstash
```

## ğŸ“¤ Utilisation - Upload de Fichiers

### Via l'Interface Web

1. AccÃ©dez Ã  http://localhost:8000/upload
2. SÃ©lectionnez un fichier CSV ou JSON
3. Cliquez sur "Upload"
4. Visualisez la prÃ©visualisation des donnÃ©es

### Via API (cURL)

**Upload d'un fichier CSV :**
```bash
curl -X POST -F "file=@votre_fichier.csv" http://localhost:8000/upload
```

**Upload d'un fichier JSON :**
```bash
curl -X POST -F "file=@votre_fichier.json" http://localhost:8000/upload
```

### Formats de Fichiers SupportÃ©s

#### CSV
```csv
timestamp,level,message
2024-01-01T10:00:00Z,INFO,Application started
2024-01-01T10:05:00Z,ERROR,Connection failed
```

#### JSON
```json
{"timestamp": "2024-01-01T10:00:00Z", "level": "INFO", "message": "Application started"}
{"timestamp": "2024-01-01T10:05:00Z", "level": "ERROR", "message": "Connection failed"}
```

## ğŸ”„ Pipeline de Traitement des Logs

### Workflow

1. **Upload** â†’ Fichier tÃ©lÃ©chargÃ© via Flask (`/upload`)
2. **Sauvegarde** â†’ StockÃ© dans `./data/uploads/`
3. **MÃ©tadonnÃ©es** â†’ EnregistrÃ©es dans MongoDB (collection `uploads`)
4. **Traitement** â†’ Logstash dÃ©tecte et parse le fichier
5. **Indexation** â†’ Les logs sont envoyÃ©s vers Elasticsearch
6. **Visualisation** â†’ DonnÃ©es disponibles dans Kibana

### Pipelines Logstash

- **CSV Pipeline** : Parse les fichiers `.csv` â†’ Index `logs-saas-csv`
- **JSON Pipeline** : Parse les fichiers `.json` â†’ Index `logs-saas-json`

## ğŸ“Š Configuration Kibana

### PremiÃ¨re Configuration

1. AccÃ©dez Ã  http://localhost:5601
2. Allez dans **Stack Management** â†’ **Index Patterns**
3. CrÃ©ez un index pattern :
   - Pattern name : `logs-saas-*`
   - Time field : `@timestamp`
4. AccÃ©dez Ã  **Discover** pour explorer vos logs

### CrÃ©ation de Visualisations

- **Management** â†’ **Visualize Library** â†’ **Create visualization**
- Types disponibles : Line chart, Bar chart, Pie chart, Data table, etc.

## ğŸ› ï¸ DÃ©pannage

### âš ï¸ ProblÃ¨me de Permissions (Erreur EACCES ou AccessDeniedException)

**SymptÃ´mes** : Elasticsearch ou Kibana redÃ©marrent en boucle avec des erreurs de permissions

**Solution** :
```bash
# ArrÃªter tous les services
docker compose down

# Corriger les permissions des dossiers de donnÃ©es
sudo chmod -R 777 data/

# Ou recrÃ©er les dossiers si nÃ©cessaire
sudo rm -rf data/elasticsearch data/kibana data/logstash
sudo mkdir -p data/elasticsearch data/kibana data/logstash data/uploads
sudo chmod -R 777 data/

# RedÃ©marrer les services
docker compose up -d
```

### Les services ne dÃ©marrent pas

```bash
# VÃ©rifier les logs
docker compose logs

# VÃ©rifier l'Ã©tat des services
docker compose ps

# RedÃ©marrer un service spÃ©cifique
docker compose restart webapp
docker compose restart elasticsearch
```

### Elasticsearch ne dÃ©marre pas (mÃ©moire insuffisante)

Ajustez les paramÃ¨tres Java dans `docker-compose.yml` :
```yaml
ES_JAVA_OPTS=-Xms256m -Xmx256m  # RÃ©duit de 512m Ã  256m
```

### Kibana en boucle de redÃ©marrage

1. **VÃ©rifier les logs** :
```bash
docker logs kibana --tail 50
```

2. **Si erreur de permissions**, suivre la solution ci-dessus

3. **Attendre qu'Elasticsearch soit prÃªt** (peut prendre 30-60 secondes au dÃ©marrage)

### Les fichiers uploadÃ©s ne sont pas traitÃ©s

1. VÃ©rifiez que Logstash est dÃ©marrÃ© :
```bash
docker compose ps logstash
```

2. Consultez les logs Logstash :
```bash
docker logs -f logstash
```

3. VÃ©rifiez que les fichiers sont dans `./data/uploads/`

### MongoDB n'est pas accessible

```bash
# RedÃ©marrer MongoDB
docker compose restart mongodb

# VÃ©rifier les logs
docker logs mongodb
```

## ğŸ§ª Tests et Validation

### âš¡ Test Rapide de Tous les Services

Utilisez le script de test automatisÃ© :

```bash
./test-services.sh
```

Ce script vÃ©rifie automatiquement :
- âœ… AccessibilitÃ© de tous les services web
- âœ… Ã‰tat des APIs (Elasticsearch, Flask)
- âœ… Connexion MongoDB et Redis
- âœ… Ã‰tat des conteneurs Docker

### Test Complet du Workflow

1. **CrÃ©er un fichier de test** :
```bash
cat > test.csv << EOF
timestamp,level,message
2024-11-08T10:00:00Z,INFO,Test log 1
2024-11-08T10:01:00Z,WARN,Test log 2
2024-11-08T10:02:00Z,ERROR,Test log 3
EOF
```

2. **Upload le fichier** :
```bash
curl -X POST -F "file=@test.csv" http://localhost:8000/upload
```

3. **VÃ©rifier dans MongoDB** (2 options) :

**Via CLI** :
```bash
docker exec -it mongodb mongosh --eval "use monitoring; db.uploads.find().pretty()"
```

**Via Mongo Express** :
- Ouvrez http://localhost:8081
- Connectez-vous avec `admin` / `admin123`
- Naviguez vers la base `monitoring` â†’ collection `uploads`
- Visualisez les mÃ©tadonnÃ©es du fichier uploadÃ©

4. **Attendre 10-30 secondes** pour le traitement Logstash

5. **VÃ©rifier dans Elasticsearch** :
```bash
curl http://localhost:9200/logs-saas-csv/_search?pretty
```

6. **Visualiser dans Kibana** : http://localhost:5601

## ğŸ“ˆ Monitoring et MÃ©triques

### Health Checks

```bash
# Elasticsearch
curl http://localhost:9200/_cluster/health?pretty

# Webapp Flask
curl http://localhost:8000


# Kibana
curl http://localhost:5601/api/status
```

### Statistiques des Index

```bash
# Nombre de documents par index
curl http://localhost:9200/_cat/count/logs-saas-*?v

# Taille des index
curl http://localhost:9200/_cat/indices/logs-saas-*?v&s=store.size:desc
```

## ğŸ” SÃ©curitÃ©

âš ï¸ **Note de sÃ©curitÃ©** : Cette configuration est prÃ©vue pour le **dÃ©veloppement uniquement**.

### Identifiants par DÃ©faut

ğŸ“„ Consultez le fichier **[CREDENTIALS.md](./CREDENTIALS.md)** pour la liste complÃ¨te des identifiants.

**AccÃ¨s rapide** :
- Mongo Express : `admin` / `admin123`
- Autres services : Authentification dÃ©sactivÃ©e en mode dÃ©veloppement

### Pour la Production

Activez impÃ©rativement :
- âœ… L'authentification Elasticsearch/Kibana (X-Pack Security)
- âœ… HTTPS/TLS pour tous les services
- âœ… Variables d'environnement sÃ©curisÃ©es (Docker Secrets)
- âœ… Authentification MongoDB avec utilisateurs dÃ©diÃ©s
- âœ… Mot de passe Redis
- âœ… Rate limiting sur l'API Flask
- âœ… Changez tous les mots de passe par dÃ©faut

## ğŸ“ Technologies UtilisÃ©es

- **Python 3.11** - Application Flask
- **Flask 2.3.2** - Framework web
- **Elasticsearch 8.10.3** - Moteur de recherche
- **Kibana 8.10.3** - Visualisation des logs
- **Logstash 8.10.3** - Pipeline de traitement
- **MongoDB 7** - Base de donnÃ©es NoSQL
- **Mongo Express 1.0.2** - Interface d'administration MongoDB
- **Redis 7** - Cache en mÃ©moire
- **Docker & Docker Compose** - Conteneurisation et orchestration

## ğŸ¯ Cas d'Usage et Exemples

### Visualiser les MÃ©tadonnÃ©es dans Mongo Express

1. **AccÃ¨s** : http://localhost:8081 (admin / admin123)
2. **Navigation** : Base `monitoring` â†’ Collection `uploads`
3. **Visualisation** : Liste de tous les fichiers uploadÃ©s avec leurs mÃ©tadonnÃ©es

### RequÃªtes MongoDB Utiles

```javascript
// Compter tous les uploads
db.uploads.countDocuments()

// Trouver les uploads en erreur
db.uploads.find({status: "error"})

// Statistiques par extension
db.uploads.aggregate([
  { $group: { _id: "$extension", count: { $sum: 1 } } }
])

// Uploads des derniÃ¨res 24h
db.uploads.find({
  uploaded_at: { $gte: new Date(Date.now() - 24*60*60*1000).toISOString() }
})
```

### Pipeline ELK Complet

1. **Upload** â†’ Flask enregistre le fichier et les mÃ©tadonnÃ©es
2. **Stockage** â†’ Fichier dans `data/uploads/`, mÃ©tadonnÃ©es dans MongoDB
3. **Traitement** â†’ Logstash parse et transforme les logs
4. **Indexation** â†’ Elasticsearch stocke les logs indexÃ©s
5. **Visualisation** â†’ Kibana pour l'analyse, Mongo Express pour les mÃ©tadonnÃ©es

## ğŸ‘¥ Auteurs

Projet rÃ©alisÃ© dans le cadre du cours de Monitoring et ELK Stack.

## ğŸ“… Date

25 novembre 2025

---

**Bon monitoring ! ğŸ“ŠğŸš€**
